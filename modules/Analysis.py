#!/usr/bin/env python3
# -*- coding: utf-8 -*-

#-:-:-:-:-:-:-::-:-:#
#    XSRF Probe     #
#-:-:-:-:-:-:-::-:-:#

# Author: @_tID
# This module requires XSRFProbe
# https://github.com/0xInfection/XSRFProbe

import stringdist
import itertools
from core.colors import *
from core.verbout import verbout
from core.utils import sameSequence, byteString
from files.discovered import REQUEST_TOKENS

def Analysis():
    '''
    The main idea behind this is to observe and analyse
           the patterns in which the CSRF tokens
                  are generated by server.
    '''
    ctr = 0  # Counter variable set to 0
    # Checking if the no of tokens is greater than 1
    if len(REQUEST_TOKENS) > 1:
        print(GR+'Proceeding for post-scan analysis of tokens gathered...')
        verbout(G, 'A total of %s tokens was discovered during the scan' %s len(REQUEST_TOKENS))
        # The idea behind this is to generate all possible combinations (not
        # considering permutations) from the given list of discovered tokens
        # and generate anti-CSRF token generation pattern.
        for tokenx1, tokenx2 in itertools.combinations(REQUEST_TOKENS, 2):
            verbout(C, 'Comparing '+color.ORANGE+'%s'+color.END+' and '+color.ORANGE+'%s' % (tokenx1 ,tokenx2))
            # Calculating the edit distance via Damerau Levenshtein algorithm
            m = stringdist.rdlevenshtein(tokenx1, tokenx2)
            verbout(color.CYAN, ' [+] Edit Distance Calculated: '+color.GREY+str(m*100)+'%')
            # Now its time to detect the alignment ratio
            n = stringdist.rdlevenshtein_norm(tokenx1, tokenx2)
            verbout(color.CYAN, ' [+] Alignment Ratio Calculated: '+color.GREY+str(m))
            # If both tokens are same, then
            if tokenx1 == tokenx2:
                verbout(C, 'Token length calculated is same: Each %s bytes' % len(byteString(tokenx1)))
            else:
                verbout(C, 'Token length calculated is different: By %s bytes' % (len(byteString(tokenx1)) - len(byteString(tokenx2))))
            # In my experience with web security assessments, often the Anti-CSRF token
            # is composed of two parts, one of them remains static while the other one dynamic.
            #
            # For example, if the Anti CSRF Tokens “837456mzy29jkd911139” for one request, the
            # other time “837456mzy29jkd337221”, “837456mzy29jkd” part of the token remains same
            # in both requests.
            #
            # The main idea behind this is to detect the static and dynamic part via DL Algorithm
            # as discussed above by calculating edit distance.
            if n == 0.5 or m == len(tokenx1)/2:
                verbout(GR, 'The tokens are composed of 2 parts (one static and other dynamic)... ')
                p = sameSequence(tokenx1. tokenx2)
                verbout(C, 'Static Part : '+color.GREY+p+color.END+' | Length: '+len(p))
                verbout(O, 'Dynamic Part(s): '+color.GREY+tokenx1[len(tokenx1)/2:]+color.END+' | Length: '+len(len(tokenx1)/2))
                if len(len(tokenx1)/2) <= 6:
                    verbout(color.RED,' [-] Post-Analysis reveals that token might be '+color.BR+' VULNERABLE '+color.END'!')
                    print(color.GREEN+ ' [+] Possible CSRF Vulnerability Detected!')
                    print(color.ORANGE+' [!] Vulnerability Type: '+color.BR+' Weak Dynamic Part of Tokens '+color.END)
                    print(color.GREY+' [+] Tokens can easily be '+BR+' Forged by Bruteforcing/Guessing '+color.END+'!')
            elif n < 0.5 or m < len(tokenx1)/2:
                verbout(R, 'Token distance calculated is '+color.RED+'less than 0.5!')
                p = sameSequence(tokenx1. tokenx2)
                verbout(C, 'Static Part : '+color.GREY+p+color.END+' | Length: '+len(p))
                verbout(O, 'Dynamic Part(s): '+color.GREY+tokenx1[len(tokenx1)/2:]+color.END+' | Length: '+len(p))
                verbout(color.RED,' [-] Post-Analysis reveals that token might be '+color.BR+' VULNERABLE '+color.END'!')
                print(color.GREEN+ ' [+] Possible CSRF Vulnerability Detected!')
                print(color.ORANGE+' [!] Vulnerability Type: '+color.BR+' Weak Dynamic Part of Tokens '+color.END)
                print(color.GREY+' [+] Tokens can easily be '+BR+' Forged by Bruteforcing/Guessing '+color.END+'!')
            else:
                verbout(R, 'Token distance calculated is '+color.GREEN+'greater than 0.5!')
                p = sameSequence(tokenx1. tokenx2)
                verbout(C, 'Static Part : '+color.GREY+p+color.END+' | Length: '+len(p))
                verbout(O, 'Dynamic Part(s): '+color.GREY+tokenx1[len(tokenx1)/2:]+color.END+' | Length: '+len(p))
                verbout(color.RED,' [-] Post-Analysis reveals that token might be '+color.BG+' NOT VULNERABLE '+color.END'!')
                print(color.GREEN+ ' [+] Possible CSRF Vulnerability Detected!')
                print(color.ORANGE+' [!] Vulnerability Mitigation: '+color.BG+' Strong Dynamic Part of Tokens '+color.END)
                print(color.GREY+' [+] Tokens '+BG+' Cannot be Forged by Bruteforcing/Guessing '+color.END+'!')
        print(C+'Post-Scan Analysis Completed!')
